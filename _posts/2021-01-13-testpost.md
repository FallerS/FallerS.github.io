---
layout: post
title: Test for jupyter notebook transformation
subtitle: checking
published: true
---

# Title



This first blog post serves as basis for the upcoming posts and topics to get some of the very basics out of the way. 
General Python and finance knowledge is assumed. There are also various sources for Pythong in general and finance-related topicsn in specific online, some can be found in the resources of this blog. 

Most of these basics rely on the online courses by [Edhec Risk Institute](https://risk.edhec.edu/who-we-are) which can be found on [Coursera](https://www.coursera.org/specializations/investment-management-python-machine-learning). I can only recommend taking these courses as much of the content is free to access without payment. 

Let's start with the very basics which we will be using in the following posts on more interesting topics: 
* data and data-source
* packages and basic functions we will be using. 

Some of the functions build on each other. The functions will be used in later posts with a short notice of this post. 
Used packages most prominently include pandas, numpy, scipy and indirectly some matplotlib


```python
import pandas as pd
import numpy as np

%load_ext autoreload
%autoreload 2
```

## Data-source

We will be using part of [Kenneth R. Frenchs data library](https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html), specifically the 30 Industry Portfolios.csv file.
The file includes several datasets one after the next in the samle sheet based on weighting schemes. We will be working with the value-weighted dataset which begins with row 12 for the indusries and ends based in the last update somewhere in 2020111 or row 1145+. simply copy this dataset, first row being the industries, in a separate csv-file with the name ind30_m_valueweight_rets.  

We will now load and adjust the data to make it more convinient to work with and take a look at the data. 
the file path may need to be adjusted depending where the .csv fiel is stored
For now we will also only take the data up until 2000.

```python
# read in csv as pandas DataFrame, define header and index-column
ind = pd.read_csv("ind30_m_valueweight_rets.CSV", header=0, index_col=0)/100
# define index as month-date
ind.index = pd.to_datetime(ind.index, format="%Y%m").to_period('M')
#reduce data until year 2018 for ease of use
ind = ind[:"2018"]
# strip trailing spaces
ind.columns = ind.columns.str.strip()
```

```python
# check columns to see the industries
ind.columns
```




    Index(['Food', 'Beer', 'Smoke', 'Games', 'Books', 'Hshld', 'Clths', 'Hlth',
           'Chems', 'Txtls', 'Cnstr', 'Steel', 'FabPr', 'ElcEq', 'Autos', 'Carry',
           'Mines', 'Coal', 'Oil', 'Util', 'Telcm', 'Servs', 'BusEq', 'Paper',
           'Trans', 'Whlsl', 'Rtail', 'Meals', 'Fin', 'Other'],
          dtype='object')



```python
#take a look at the data
print(ind.shape)
ind.head()
```

    (1110, 30)





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Food</th>
      <th>Beer</th>
      <th>Smoke</th>
      <th>Games</th>
      <th>Books</th>
      <th>Hshld</th>
      <th>Clths</th>
      <th>Hlth</th>
      <th>Chems</th>
      <th>Txtls</th>
      <th>...</th>
      <th>Telcm</th>
      <th>Servs</th>
      <th>BusEq</th>
      <th>Paper</th>
      <th>Trans</th>
      <th>Whlsl</th>
      <th>Rtail</th>
      <th>Meals</th>
      <th>Fin</th>
      <th>Other</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1926-07</th>
      <td>0.0056</td>
      <td>-0.0519</td>
      <td>0.0129</td>
      <td>0.0293</td>
      <td>0.1097</td>
      <td>-0.0048</td>
      <td>0.0808</td>
      <td>0.0177</td>
      <td>0.0814</td>
      <td>0.0039</td>
      <td>...</td>
      <td>0.0083</td>
      <td>0.0922</td>
      <td>0.0206</td>
      <td>0.0770</td>
      <td>0.0193</td>
      <td>-0.2379</td>
      <td>0.0007</td>
      <td>0.0187</td>
      <td>0.0037</td>
      <td>0.0520</td>
    </tr>
    <tr>
      <th>1926-08</th>
      <td>0.0259</td>
      <td>0.2703</td>
      <td>0.0650</td>
      <td>0.0055</td>
      <td>0.1001</td>
      <td>-0.0358</td>
      <td>-0.0251</td>
      <td>0.0425</td>
      <td>0.0550</td>
      <td>0.0797</td>
      <td>...</td>
      <td>0.0217</td>
      <td>0.0202</td>
      <td>0.0439</td>
      <td>-0.0238</td>
      <td>0.0488</td>
      <td>0.0539</td>
      <td>-0.0075</td>
      <td>-0.0013</td>
      <td>0.0446</td>
      <td>0.0676</td>
    </tr>
    <tr>
      <th>1926-09</th>
      <td>0.0116</td>
      <td>0.0402</td>
      <td>0.0126</td>
      <td>0.0658</td>
      <td>-0.0099</td>
      <td>0.0073</td>
      <td>-0.0051</td>
      <td>0.0069</td>
      <td>0.0533</td>
      <td>0.0230</td>
      <td>...</td>
      <td>0.0241</td>
      <td>0.0225</td>
      <td>0.0019</td>
      <td>-0.0554</td>
      <td>0.0005</td>
      <td>-0.0787</td>
      <td>0.0025</td>
      <td>-0.0056</td>
      <td>-0.0123</td>
      <td>-0.0386</td>
    </tr>
    <tr>
      <th>1926-10</th>
      <td>-0.0306</td>
      <td>-0.0331</td>
      <td>0.0106</td>
      <td>-0.0476</td>
      <td>0.0947</td>
      <td>-0.0468</td>
      <td>0.0012</td>
      <td>-0.0057</td>
      <td>-0.0476</td>
      <td>0.0100</td>
      <td>...</td>
      <td>-0.0011</td>
      <td>-0.0200</td>
      <td>-0.0109</td>
      <td>-0.0508</td>
      <td>-0.0264</td>
      <td>-0.1538</td>
      <td>-0.0220</td>
      <td>-0.0411</td>
      <td>-0.0516</td>
      <td>-0.0849</td>
    </tr>
    <tr>
      <th>1926-11</th>
      <td>0.0635</td>
      <td>0.0729</td>
      <td>0.0455</td>
      <td>0.0166</td>
      <td>-0.0580</td>
      <td>-0.0054</td>
      <td>0.0187</td>
      <td>0.0542</td>
      <td>0.0520</td>
      <td>0.0310</td>
      <td>...</td>
      <td>0.0163</td>
      <td>0.0377</td>
      <td>0.0364</td>
      <td>0.0384</td>
      <td>0.0160</td>
      <td>0.0467</td>
      <td>0.0652</td>
      <td>0.0433</td>
      <td>0.0224</td>
      <td>0.0400</td>
    </tr>
  </tbody>
</table>
<p>5 rows Ã— 30 columns</p>
</div>



### Drawdown
We want to set up some key figures for the returns data we now have. 
The drawdown function which provides a time series, as well as local and global drawdown for a given pandas time series: 

```python
def drawdown(return_series: pd.Series):
    """Takes time series of asset returns.
       returns DataFrame with columns
       wealth index, 
       previous peaks, 
       the percentage drawdown
    """
    wealth_index = 100*(1+return_series).cumprod()
    previous_peaks = wealth_index.cummax()
    drawdowns = (wealth_index - previous_peaks)/previous_peaks
    return pd.DataFrame({"Wealth": wealth_index, 
                         "Previous Peak": previous_peaks, 
                         "Drawdown": drawdowns})
```

We can easily look up the series for one of our industry portfolios and check for the drawdowns in this time or look up the maximum dardown and time of this drawdown.

```python
drawdown(ind['Smoke'])['Drawdown'].plot.line()
```




    <matplotlib.axes._subplots.AxesSubplot at 0x7f8b58e0e590>




![png](2021-01-13-testpost/output_10_1.png)


```python
# take time series of "Smoke" from the DataFrame for the drawdown function
max_drawdown = round(drawdown(ind['Smoke'])['Drawdown'].min(),4)*100
max_drawdown_date = (drawdown(ind['Smoke'])['Drawdown'].idxmin())
print(f'The maximum drawdown until end of 2018 for Smoke was {max_drawdown}% on {max_drawdown_date}.')
```

    The maximum drawdown until end of 2018 for Smoke was -59.88% on 2000-02.


### annualize returns

```python
def annualize_ret(r, periods_per_year):
    """
    Annualizes returns of return series
    Requires return series
    and periods per year
    """
    compounded_growth = (1+r).prod()
    n_periods = r.shape[0]
    return compounded_growth**(periods_per_year/n_periods)-1
```

```python
ann_ret_smoke = annualize_ret(ind['Smoke'],12)
print(f'The annualized return of the Smoke industry from 07/1926 until 12/2018 was appr. {(ann_ret_smoke*100).round(2)}%.')
```

    The annualized return of the Smoke industry from 07/1926 until 12/2018 was appr. 12.23%.


### annualize volatility
volatility as standard deviation - annualized

```python
def annualize_vol(r, periods_per_year):
    """
    Annualizes volatility of return series
    Requires return series
    and periods per year
    """
    return r.std()*np.sqrt(periods_per_year)
```

```python
ann_vol_smoke = annualize_vol(ind['Smoke'],12)
print(f'The annualized volatility of the Smoke industry from 07/1926 until 12/2018 was appr. {(ann_vol_smoke*100).round(2)}%.')
```

    The annualized volatility of the Smoke industry from 07/1926 until 12/2018 was appr. 20.12%.


### sharpe ratio
Calculates the sharpe ratio on an annual basis. 
Unrealistic assumption to have the same riskfree rate for the complete time horizon but we are starting small :)

```python
def sharpe_ratio(r, riskfree_rate, periods_per_year):
    """
    Computes the annualized sharpe ratio of a set of returns
    Requires return series,  
    periods per year
    and an annual risk-free rate.
    """
    # convert the annual riskfree rate to per period
    rf_per_period = (1+riskfree_rate)**(1/periods_per_year)-1
    excess_ret = r - rf_per_period
    ann_ex_ret = annualize_ret(excess_ret, periods_per_year)
    ann_vol = annualize_vol(r, periods_per_year)
    return ann_ex_ret/ann_vol
```

```python
sr_smoke = sharpe_ratio(r=ind['Smoke'], riskfree_rate=0.02, periods_per_year=12)
print(f'The annualized sharpe ratio of the Smoke industry from 07/1926 until 12/2018 assuming a riskfree rate of 2% was appr. {(sr_smoke).round(2)}.')
```

    The annualized sharpe ratio of the Smoke industry from 07/1926 until 12/2018 assuming a riskfree rate of 2% was appr. 0.5.


### Skewness
negative skew results in more negative returns as would be expected cmopared to a normal distribution

{% raw %}
$$ S(R) = \frac{E[ (R-E(R))^3 ]}{\sigma_R^3} $$
{% endraw %}

```python
# alternatively scipy can be used: scipy.stats.skew()
def skewness(r):
    """
    Computes skewness of Series or DataFrame
    Returns a float or a Series depending n input
    """
    demeaned_r = r - r.mean()
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**3).mean()
    return exp/sigma_r**3

```

```python
skewness(ind['Smoke'])
```




    0.0038726766269701323



### Kurtosis
relates to "fatness" of tails compared to normal distributuion. Fatter tails describe more extreme outcomes as would be expected compared to a normal distribution as can be often seen with stock investments. 
Normal distribution has a kurtosis of 3, so a kurtosis > 3 related to fat tails

{% raw %}
$$ K(R) = \frac{E[ (R-E(R))^4 ]}{\sigma_R^4} $$
{% endraw %}

```python
# alternatively scipy can be used: scipy.stats.kurtosis()
def kurtosis(r):
    """
    Computes the kurtosis of the supplied Series or DataFrame
    Returns a float or a Series
    """
    demeaned_r = r - r.mean()
    # use the population standard deviation, so set dof=0
    sigma_r = r.std(ddof=0)
    exp = (demeaned_r**4).mean()
    return exp/sigma_r**4
```

```python
kurtosis(ind['Smoke'])
# well above 3 ;)
```




    6.238037198836735


